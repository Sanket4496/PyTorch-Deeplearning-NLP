{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Tensors\n",
    "Ref: https://www.learnpytorch.io/00_pytorch_fundamentals/#creating-tensors\n",
    "### Creating Tensors\n",
    "PyTorch tensors are created using `torch.tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the dimensions of a tensor using the `ndim` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieved the number from the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5,  0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([-5,0])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of dimension of the vector\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of a vector\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "MATRIX = torch.tensor([[7,8],[9,10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of dimension\n",
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape\n",
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR = torch.tensor([[[1,2,3],[4,5,6],[7,8,9]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/00-pytorch-different-tensor-dimensions.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Summarise....\n",
    "| Name | What is it? | Number of dimensions | Variable Declaration |\n",
    "|:--------:|:--------:|:--------:| :--------: |\n",
    "|  scalar  |  a single number   |  0 | Lower(a)   |\n",
    "|  vector  |  1-dimensional array |  1  | Lower(y) |\n",
    "|  matrix  |  2-dimensional array |  2  | Upper(Q) |\n",
    "| tensor | an n-dimensional array | n | Upper(X) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<image src=\"images/00-scalar-vector-matrix-tensor.png\" width=30% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0202, 0.3253, 0.8353, 0.3862],\n",
       "         [0.7080, 0.9983, 0.1873, 0.4760],\n",
       "         [0.9020, 0.1138, 0.1311, 0.4415]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size(3, 4)\n",
    "random_tensor = torch.rand(size=(3, 4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The flexibility of `torch.rand()` is that we can adjust the size to be whatever we want.\n",
    "- For example, say you wanted a random tensor in the common image shape of `[224, 224, 3]` (`[height, width, color_channels]`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeros and Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3, 5))\n",
    "zeros, zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a range and tensors like\n",
    "`torch.arange(start, end, step)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_ten = torch.arange(0, 10, 1)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sometimes you might want one tensor of a certain type with the same shape as another tensor. \n",
    "- For Example, a tensor of all zeros with the same shape as a previous tensor.\n",
    "- To do so you can use `torch.zeros_like(input)` or `torch.ones_like(input)` which return a tensor filled with `zeros or ones` in the same shape as the `input` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of zeros similar to another tensor\n",
    "ten_zeros = torch.zeros_like(input=zero_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Datatypes\n",
    "- There are many different tensor datatypes available in PyTorch. \n",
    "- Some are specific for CPU and some are better for GPU.\n",
    "- Getting to know which one can take some time.\n",
    "- Generally if you see `torch.cuda` anywhere, the tensor is being used for `GPU` (since `Nvidia GPUs` use a computing toolkit called `CUDA`).\n",
    "- The most common type (and generally the default) is `torch.float32` or `torch.float`. This is referred to as \"`32-bit floating point`\".\n",
    "- But there's also 16-bit floating point (`torch.float16 or torch.half`) and 64-bit floating point (`torch.float64 or torch.double`).\n",
    "- And to confuse things even more there's also 8-bit, 16-bit, 32-bit and 64-bit integers.\n",
    "- The reason for all of these is to do with precision in computing. Precision is the amount of detail used to describe a number.\n",
    "- The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
    "- This matters in deep learning and numerical computing because you're making so many operations, the more detail you have to calculate on, the more compute you have to use.\n",
    "- So lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluation metrics like accuracy (faster to compute but less accurate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with specific datatype\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=None, device=None, requires_grad=False) # Default dtype = float32, Default device CPU otherwise CUDA if mentioned, requires_grad means record the gradient\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from shape issues (tensor shapes don't match up), two of the other most common issues you'll come across in PyTorch are **datatype and device issues**. For example, one of tensors is `torch.float32` and the other is `torch.float16` (*PyTorch often likes tensors to be the same format*).Or one of your tensors is on the `CPU` and the other is on the `GPU` (*PyTorch likes calculations between tensors to be on the same device*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Information From tensors\n",
    "Three of the most common attributes we want to findout about tensors are:\n",
    "1. `shape`: What shape is the tensor? (Some operations require specific shape rules)\n",
    "2. `dtype`: What datatype are the elements within the tensor stored in?\n",
    "3. `device`: What device is the tensor stored on? (usually GPU or CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9679, 0.8841, 0.3502, 0.5061],\n",
      "        [0.0281, 0.3315, 0.4322, 0.7651],\n",
      "        [0.4030, 0.3256, 0.0921, 0.5250]])\n",
      "Shape: torch.Size([3, 4])\n",
      "Datatype: torch.float32\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "some_tensor = torch.rand(3, 4)\n",
    "# Find the details\n",
    "print(some_tensor)\n",
    "print(f'Shape: {some_tensor.shape}')\n",
    "print(f'Datatype: {some_tensor.dtype}')\n",
    "print(f'Device: {some_tensor.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "    Note: When you run into issues in PyTorch, it's very often one to do with one of the three attributes above. So when the error messages show up, sing yourself a little song called \"what, what, where\":\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating tensors\n",
    "In deep learning, data (images, text, video, audio, protein structures, etc) gets represented as tensors.\n",
    "\n",
    "A model learns by investigating those tensors and performing a series of operations (could be 1,000,000s+) on tensors to create a representation of the patterns in the input data.\n",
    "\n",
    "These operations are often a wonderful dance between:\n",
    "1. Addition\n",
    "2. Substraction\n",
    "3. Multiplication (element-wise)\n",
    "4. Division\n",
    "5. Matrix multiplication\n",
    "\n",
    "And that's it. Sure there are a few more here and there but these are the basic building blocks of neural networks.\n",
    "\n",
    "Stacking these building blocks in the right way, you can create the most sophisticated of neural networks (just like lego!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Addition\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply it by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the tensor values above didn't end up being tensor([110, 120, 130]), this is because the values inside the tensor don't change unless they're reassigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract and reassign\n",
    "tensor = tensor - 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add and reassign\n",
    "tensor += 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch also has a bunch of built-in functions like `torch.mul()` (short for multiplication) and `torch.add()` to perform basic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elementwise multiplication\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "- PyTorch implements matrix multiplication functionality using `torch.matmul()` method.\n",
    "- `@` in Python is the symbol for matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case-1: If both tensors are 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case-2: If Both are 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0833, 0.6784],\n",
       "        [0.8199, 0.5251]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand(size=(2,2))\n",
    "B = torch.rand(size=(2,2))\n",
    "torch.matmul(A,B) # Matrix-Matrix Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case-3: 1D @ 2D\n",
    "In this case, the first tensor is treated as a row-vector by prepending a 1 to its dimension. After the matrix multiplication the prepend dimension is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13, 16])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2]) # Shape(2,)\n",
    "B = torch.tensor([[3,4],[5,6]]) # Shape(2,2)\n",
    "# Inorder to support matrix multiplication shape of a must be (1, 2)\n",
    "# Internally a is treated as [[1,2]], now shape is (1, 2)\n",
    "# Matrix Multiplication is performed and result is [[13, 16]]\n",
    "# Remove the Prepending Dimension: [13, 16]\n",
    "torch.matmul(a,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 4: 2D @ 1D\n",
    "The second tensor is treated as a column vector by appending a 1 to its dimension. The result is a matrix-vector product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17, 39])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1,2],[3,4]]) # Shape(2,2)\n",
    "b = torch.tensor([5,6]) # Shape(2,)\n",
    "# b will be converted as [[5],[6]] now Shape(2,1)\n",
    "# Multiplication result: [[17],[19]] now Shape(2,1)\n",
    "# Remove the prepend dimension: [17, 19] now Shape(2, )\n",
    "A @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case-5: Batched Matrix Multiplication(N-Dimensional tensors)\n",
    "Steps are as follows\n",
    "1. The last two dimensions are treated as matrices.\n",
    "2. All dimensions before the last two are treated as batch dimensions\n",
    "3. Batch dimensions must either:\n",
    "   1. Match Exactly\n",
    "   2. Be Broadcasted to each other.\n",
    "4. The Output shape combines broadcasted batch dimensions and the resulting matrix product dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# Batched Matrix multiplication\n",
    "A = torch.rand(2, 3, 4) # Shape: (2, 3, 4)\n",
    "B = torch.rand(2, 4, 5) # Shape: (2, 4, 5)\n",
    "result = torch.matmul(A, B) # Shape: (2, 3, 5)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<image src=\"images/batched-matrix-multiplication.jpg\" width=30%/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting batch dimensions\n",
    "A = torch.rand(1, 3, 4)\n",
    "B = torch.rand(2, 4, 5)\n",
    "result = A @ B\n",
    "print(result.shape) # Shape: (2, 3, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<image src=\"images/broadcasting-batch-dimension.jpg\" width=30%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D and N-dimensional batched multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1.0, 2.0])\n",
    "B = torch.randn(2, 2, 3)\n",
    "# Prepend a Dimension to a: a = [[1, 2]] Shape(1, 2)\n",
    "# For the first matrix in B, matrix dimensions : (1 x 2) x (2 x 3) = (1 x 3)\n",
    "# For the Second Matrix in B, matrix dimensions: (1 x 2) x (2 x 3) = (1 x 3)\n",
    "# Combine result: Shape(2, 3)\n",
    "result = torch.matmul(a, B) \n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose\n",
    "`torch.transpose(input, dim0, dim1)` It swaps the two specified dimension of the input tensor. It rearanges the data in the tensor along the specified axes without changing the underlying data.\n",
    "\n",
    "#### Function Paramter\n",
    "1. input: The tensor you want to transpose\n",
    "2. dim0: The first dimension to swap\n",
    "3. dim1: The second dimension to swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3],\n",
       "        [2, 4]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose of a matrix \n",
    "tensor = torch.tensor([[1, 2], [3, 4]])\n",
    "tensor.T # torch.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [5, 6]],\n",
       "\n",
       "        [[3, 4],\n",
       "         [7, 8]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swapping Axes of a 3D Tensor\n",
    "a = torch.tensor([[[1,2],[3,4]],\n",
    "                  [[5,6],[7,8]]])\n",
    "b = torch.transpose(a, 0, 1)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tensor has 3 dimensions:\n",
    "- Dimension 0: 2 matrices (or slices): [[1, 2], [3, 4]] and [[5, 6], [7, 8]].\n",
    "- Dimension 1: Each matrix has 2 rows.\n",
    "- Dimension 2: Each row has 2 columns.\n",
    "  \n",
    "Before Transpose:\n",
    "- dim0 (Axis 0): Represents slices [[1, 2], [3, 4]] and [[5, 6], [7, 8]].\n",
    "- dim1 (Axis 1): Represents rows within each slice.\n",
    "\n",
    "After Swapping dim0 and dim1:\n",
    "- What used to be rows (dim1) now become slices (dim0).\n",
    "- What used to be slices (dim0) now become rows (dim1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 5],\n",
       "         [3, 7]],\n",
       "\n",
       "        [[2, 6],\n",
       "         [4, 8]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(a, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 3],\n",
       "         [2, 4]],\n",
       "\n",
       "        [[5, 7],\n",
       "         [6, 8]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(a, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural networks are full of matrix multiplications and dot products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `torch.nn.Linear()` module, also known as a feed-forward layer or fully connected layer, implements matrix multiplication between an input `x` and a weights matrix `A`.\n",
    "$$y=x.A^T + b$$\n",
    "\n",
    "Where \n",
    "- `x` is the input to the layer\n",
    "- `A` is the weights matrix created by the layer, this starts out as random numbers that get adjusted as a neural network learns to better represent patterns in the data (notice the \"`T`\", that's because the weights matrix gets transposed).\n",
    "- `b` is the bias term used to slightly offset the weights and inputs.\n",
    "- `y` is the output (a manipulation of the input in the hopes to discover patterns in it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "Output: \n",
      "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
      "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42) # To make the things reproducible\n",
    "linear = torch.nn.Linear(in_features=2, # Matches inner dimension of Input\n",
    "                         out_features=6)\n",
    "x = torch.tensor([[1, 2],\n",
    "                  [3, 4],\n",
    "                  [5, 6]], dtype=torch.float32)\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output: \\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What happens if you change in_features from 2 to 3 above? Does it error? How could you change the shape of the input (x) to accommodate to the error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "Output: \n",
      "tensor([[0.9332, 0.8805, 3.0149, 1.5545, 1.8186, 2.0634],\n",
      "        [1.7186, 1.4009, 3.5818, 1.7408, 2.6017, 2.5123]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42) # To make the things reproducible\n",
    "linear = torch.nn.Linear(in_features=3, # Matches inner dimension of Input\n",
    "                         out_features=6)\n",
    "x = torch.tensor([[1, 2],\n",
    "                  [3, 4],\n",
    "                  [5, 6]], dtype=torch.float32)\n",
    "output = linear(x.T)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output: \\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the min, max, mean, sum, etc (aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find the max, min, mean and sum of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: 0\n",
      "Maximum: 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n"
     ]
    }
   ],
   "source": [
    "print(f\"Minimum: {x.min()}\")\n",
    "print(f\"Maximum: {x.max()}\")\n",
    "print(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatypes\n",
    "print(f\"Sum: {x.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional min/max\n",
    "You can also find the index of a tensor where the max or minimum occurs with `torch.argmax()` and `torch.argmin()` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index where max value occur: 9\n",
      "Index where min value occur: 0\n"
     ]
    }
   ],
   "source": [
    "# Return index of max and min values\n",
    "print(f\"Index where max value occur: {x.argmax()}\")\n",
    "print(f\"Index where min value occur: {x.argmin()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change tensor datatype\n",
    "As mentioned, a common issue with deep learning operations is having your tensors in different datatypes.\n",
    "\n",
    "If one tensor is in `torch.float64` and another is in `torch.float32`, you might run into some errors.\n",
    "\n",
    "But there's a fix.\n",
    "\n",
    "You can change the datatypes of tensors using `torch.Tensor.type(dtype=None)` where the `dtype` parameter is the datatype you'd like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and check the datatype\n",
    "tensor = torch.arange(10.,100.,10.)\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a float16 tensor from the above tensor\n",
    "tensor_float16 = tensor.type(torch.float16)\n",
    "tensor_float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an int8 tensor\n",
    "tensor_int8 = tensor.type(torch.int8)\n",
    "tensor_int8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Exercise:` So far we've covered a fair few tensor methods but there's a bunch more in the `torch.Tensor` [documentation](https://pytorch.org/docs/stable/tensors.html), I'd recommend spending 10-minutes scrolling through and looking into any that catch your eye. Click on them and then write them out in code yourself to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([ 0.7851-1.1949j, -0.6993+0.6774j,  0.9349+0.5778j, -0.5415-0.5308j])\n",
      "x_real: tensor([ 0.7851, -0.6993,  0.9349, -0.5415])\n"
     ]
    }
   ],
   "source": [
    "# Tensor.real\n",
    "# Returns a new tensor containing real values of the self tensor for a complex-valued input tensor. \n",
    "# The returned tensor and self share the same underlying storage.\n",
    "# Returns self if self is a real-valued tensor tensor.\n",
    "x = torch.randn(4, dtype=torch.cfloat)\n",
    "print(f\"x: {x}\")\n",
    "print(f\"x_real: {x.real}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.abs()\n",
    "torch.abs(torch.tensor([-1, -2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([ 1.3525,  0.6863, -0.3278,  0.7950])\n",
      "Inverse_Cos_of_a: tensor([ 1.3525,  0.6863, -0.3278,  0.7950])\n"
     ]
    }
   ],
   "source": [
    "# torch.acos(): Computes the inverse cosine of each element in input.\n",
    "a = torch.randn(4)\n",
    "inverse_cos_a = torch.acos(a)\n",
    "print(f\"a: {a}\")\n",
    "print(f\"Inverse_Cos_of_a: {a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.1059e+00, -3.1359e-03, -2.0432e+00,  6.6354e-01,  6.4135e+00],\n",
       "        [ 2.7884e+00,  5.5228e-01, -4.5921e+00,  8.5628e+00,  4.4435e+00],\n",
       "        [-2.5552e+00,  6.3446e+00, -9.0685e+00,  4.4779e+00,  2.1720e+00]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.addbmm(input, batch1, batch2, *, beta=1, alpha=1, out=None)\n",
    "# Performs a batch matrix-matrix product of matrices stored in batch1 and batch2,\n",
    "# with a reduced add step (all matrix multiplications get accumulated along the first dimension).\n",
    "# input is added to the final result.\n",
    "# Ref: https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm\n",
    "M = torch.randn(3, 5)\n",
    "batch1 = torch.randn(10, 3, 4)\n",
    "batch2 = torch.randn(10, 4, 5)\n",
    "torch.addbmm(M, batch1, batch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.equal(input, other)\n",
    "# True if two tensors have the same size and elements, False otherwise.\n",
    "\n",
    "torch.equal(torch.tensor([1,2]), torch.tensor([1, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping, stacking, squeezing and unsqueezing¶\n",
    "<image src=\"images/popular_methods_reshape_view.png\" />\n",
    "\n",
    "Why do any of these?\n",
    "\n",
    "Because deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you've got shape mismatches, you'll run into errors. These methods help you make sure the right elements of your tensors are mixing with the right elements of other tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device type\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
